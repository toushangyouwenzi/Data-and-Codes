{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a15c75",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-10T09:48:05.305951Z",
     "iopub.status.busy": "2025-03-10T09:48:05.305628Z",
     "iopub.status.idle": "2025-03-10T09:48:06.046888Z",
     "shell.execute_reply": "2025-03-10T09:48:06.045938Z"
    },
    "papermill": {
     "duration": 0.747309,
     "end_time": "2025-03-10T09:48:06.048373",
     "exception": false,
     "start_time": "2025-03-10T09:48:05.301064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/all-province/all_province_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1589d363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T09:48:06.053500Z",
     "iopub.status.busy": "2025-03-10T09:48:06.053182Z",
     "iopub.status.idle": "2025-03-10T09:48:11.358373Z",
     "shell.execute_reply": "2025-03-10T09:48:11.357386Z"
    },
    "papermill": {
     "duration": 5.309277,
     "end_time": "2025-03-10T09:48:11.360008",
     "exception": false,
     "start_time": "2025-03-10T09:48:06.050731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\r\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\r\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\r\n",
      "Successfully installed torch_geometric-2.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd33fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T09:48:11.366199Z",
     "iopub.status.busy": "2025-03-10T09:48:11.365952Z",
     "iopub.status.idle": "2025-03-10T09:49:18.966914Z",
     "shell.execute_reply": "2025-03-10T09:49:18.965569Z"
    },
    "papermill": {
     "duration": 67.60657,
     "end_time": "2025-03-10T09:49:18.969198",
     "exception": false,
     "start_time": "2025-03-10T09:48:11.362628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "====== Begin Grid Search ======\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=10, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 37 (patience=10)\n",
      "Fold 1: Best Epoch = 27, Val_R² = 0.1621\n",
      "Fold 2: Best Epoch = 200, Val_R² = 0.9714\n",
      "Fold 3: Early stopping at epoch 31 (patience=10)\n",
      "Fold 3: Best Epoch = 21, Val_R² = 0.1011\n",
      "Fold 4: Early stopping at epoch 29 (patience=10)\n",
      "Fold 4: Best Epoch = 19, Val_R² = 0.0669\n",
      "Fold 5: Early stopping at epoch 29 (patience=10)\n",
      "Fold 5: Best Epoch = 19, Val_R² = 0.1140\n",
      "Combination lr=0.001, patience=10, hidden_dim=32: Avg Val_R² = 0.2831, Avg Best Epoch = 57.20\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=10, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 31 (patience=10)\n",
      "Fold 1: Best Epoch = 21, Val_R² = 0.2108\n",
      "Fold 2: Early stopping at epoch 24 (patience=10)\n",
      "Fold 2: Best Epoch = 14, Val_R² = 0.1304\n",
      "Fold 3: Best Epoch = 200, Val_R² = 0.9615\n",
      "Fold 4: Early stopping at epoch 21 (patience=10)\n",
      "Fold 4: Best Epoch = 11, Val_R² = 0.1185\n",
      "Fold 5: Early stopping at epoch 184 (patience=10)\n",
      "Fold 5: Best Epoch = 174, Val_R² = 0.9783\n",
      "Combination lr=0.001, patience=10, hidden_dim=64: Avg Val_R² = 0.4799, Avg Best Epoch = 84.00\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=10, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 101 (patience=10)\n",
      "Fold 1: Best Epoch = 91, Val_R² = 0.9649\n",
      "Fold 2: Early stopping at epoch 115 (patience=10)\n",
      "Fold 2: Best Epoch = 105, Val_R² = 0.9749\n",
      "Fold 3: Early stopping at epoch 77 (patience=10)\n",
      "Fold 3: Best Epoch = 67, Val_R² = 0.9575\n",
      "Fold 4: Early stopping at epoch 108 (patience=10)\n",
      "Fold 4: Best Epoch = 98, Val_R² = 0.9536\n",
      "Fold 5: Early stopping at epoch 110 (patience=10)\n",
      "Fold 5: Best Epoch = 100, Val_R² = 0.9783\n",
      "Combination lr=0.001, patience=10, hidden_dim=128: Avg Val_R² = 0.9658, Avg Best Epoch = 92.20\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=20, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 156 (patience=20)\n",
      "Fold 1: Best Epoch = 136, Val_R² = 0.9651\n",
      "Fold 2: Best Epoch = 200, Val_R² = 0.9720\n",
      "Fold 3: Early stopping at epoch 156 (patience=20)\n",
      "Fold 3: Best Epoch = 136, Val_R² = 0.9606\n",
      "Fold 4: Best Epoch = 200, Val_R² = 0.9487\n",
      "Fold 5: Best Epoch = 200, Val_R² = 0.9782\n",
      "Combination lr=0.001, patience=20, hidden_dim=32: Avg Val_R² = 0.9649, Avg Best Epoch = 174.40\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=20, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 111 (patience=20)\n",
      "Fold 1: Best Epoch = 91, Val_R² = 0.9682\n",
      "Fold 2: Best Epoch = 200, Val_R² = 0.9752\n",
      "Fold 3: Best Epoch = 200, Val_R² = 0.9585\n",
      "Fold 4: Best Epoch = 200, Val_R² = 0.9484\n",
      "Fold 5: Early stopping at epoch 158 (patience=20)\n",
      "Fold 5: Best Epoch = 138, Val_R² = 0.9774\n",
      "Combination lr=0.001, patience=20, hidden_dim=64: Avg Val_R² = 0.9656, Avg Best Epoch = 165.80\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=20, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 108 (patience=20)\n",
      "Fold 1: Best Epoch = 88, Val_R² = 0.9640\n",
      "Fold 2: Early stopping at epoch 140 (patience=20)\n",
      "Fold 2: Best Epoch = 120, Val_R² = 0.9708\n",
      "Fold 3: Early stopping at epoch 112 (patience=20)\n",
      "Fold 3: Best Epoch = 92, Val_R² = 0.9536\n",
      "Fold 4: Best Epoch = 193, Val_R² = 0.9579\n",
      "Fold 5: Early stopping at epoch 148 (patience=20)\n",
      "Fold 5: Best Epoch = 128, Val_R² = 0.9763\n",
      "Combination lr=0.001, patience=20, hidden_dim=128: Avg Val_R² = 0.9645, Avg Best Epoch = 124.20\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=30, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 165 (patience=30)\n",
      "Fold 1: Best Epoch = 135, Val_R² = 0.9675\n",
      "Fold 2: Best Epoch = 200, Val_R² = 0.9696\n",
      "Fold 3: Best Epoch = 200, Val_R² = 0.9500\n",
      "Fold 4: Best Epoch = 200, Val_R² = 0.9547\n",
      "Fold 5: Best Epoch = 200, Val_R² = 0.9729\n",
      "Combination lr=0.001, patience=30, hidden_dim=32: Avg Val_R² = 0.9629, Avg Best Epoch = 187.00\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=30, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 167 (patience=30)\n",
      "Fold 1: Best Epoch = 137, Val_R² = 0.9650\n",
      "Fold 2: Early stopping at epoch 177 (patience=30)\n",
      "Fold 2: Best Epoch = 147, Val_R² = 0.9731\n",
      "Fold 3: Best Epoch = 200, Val_R² = 0.9613\n",
      "Fold 4: Early stopping at epoch 175 (patience=30)\n",
      "Fold 4: Best Epoch = 145, Val_R² = 0.9575\n",
      "Fold 5: Early stopping at epoch 155 (patience=30)\n",
      "Fold 5: Best Epoch = 125, Val_R² = 0.9810\n",
      "Combination lr=0.001, patience=30, hidden_dim=64: Avg Val_R² = 0.9676, Avg Best Epoch = 150.80\n",
      "\n",
      "Testing combination: learning_rate=0.001, patience=30, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 99 (patience=30)\n",
      "Fold 1: Best Epoch = 69, Val_R² = 0.9706\n",
      "Fold 2: Early stopping at epoch 137 (patience=30)\n",
      "Fold 2: Best Epoch = 107, Val_R² = 0.9696\n",
      "Fold 3: Best Epoch = 200, Val_R² = 0.9578\n",
      "Fold 4: Early stopping at epoch 138 (patience=30)\n",
      "Fold 4: Best Epoch = 108, Val_R² = 0.9607\n",
      "Fold 5: Early stopping at epoch 158 (patience=30)\n",
      "Fold 5: Best Epoch = 128, Val_R² = 0.9813\n",
      "Combination lr=0.001, patience=30, hidden_dim=128: Avg Val_R² = 0.9680, Avg Best Epoch = 122.40\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=10, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 72 (patience=10)\n",
      "Fold 1: Best Epoch = 62, Val_R² = 0.9671\n",
      "Fold 2: Early stopping at epoch 94 (patience=10)\n",
      "Fold 2: Best Epoch = 84, Val_R² = 0.9731\n",
      "Fold 3: Early stopping at epoch 120 (patience=10)\n",
      "Fold 3: Best Epoch = 110, Val_R² = 0.9638\n",
      "Fold 4: Early stopping at epoch 68 (patience=10)\n",
      "Fold 4: Best Epoch = 58, Val_R² = 0.9431\n",
      "Fold 5: Early stopping at epoch 111 (patience=10)\n",
      "Fold 5: Best Epoch = 101, Val_R² = 0.9802\n",
      "Combination lr=0.005, patience=10, hidden_dim=32: Avg Val_R² = 0.9654, Avg Best Epoch = 83.00\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=10, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 79 (patience=10)\n",
      "Fold 1: Best Epoch = 69, Val_R² = 0.9666\n",
      "Fold 2: Early stopping at epoch 83 (patience=10)\n",
      "Fold 2: Best Epoch = 73, Val_R² = 0.9742\n",
      "Fold 3: Early stopping at epoch 52 (patience=10)\n",
      "Fold 3: Best Epoch = 42, Val_R² = 0.9338\n",
      "Fold 4: Early stopping at epoch 54 (patience=10)\n",
      "Fold 4: Best Epoch = 44, Val_R² = 0.9519\n",
      "Fold 5: Early stopping at epoch 48 (patience=10)\n",
      "Fold 5: Best Epoch = 38, Val_R² = 0.9719\n",
      "Combination lr=0.005, patience=10, hidden_dim=64: Avg Val_R² = 0.9597, Avg Best Epoch = 53.20\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=10, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 55 (patience=10)\n",
      "Fold 1: Best Epoch = 45, Val_R² = 0.9696\n",
      "Fold 2: Early stopping at epoch 92 (patience=10)\n",
      "Fold 2: Best Epoch = 82, Val_R² = 0.9750\n",
      "Fold 3: Early stopping at epoch 67 (patience=10)\n",
      "Fold 3: Best Epoch = 57, Val_R² = 0.9618\n",
      "Fold 4: Early stopping at epoch 69 (patience=10)\n",
      "Fold 4: Best Epoch = 59, Val_R² = 0.9623\n",
      "Fold 5: Early stopping at epoch 76 (patience=10)\n",
      "Fold 5: Best Epoch = 66, Val_R² = 0.9819\n",
      "Combination lr=0.005, patience=10, hidden_dim=128: Avg Val_R² = 0.9701, Avg Best Epoch = 61.80\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=20, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 95 (patience=20)\n",
      "Fold 1: Best Epoch = 75, Val_R² = 0.9679\n",
      "Fold 2: Early stopping at epoch 100 (patience=20)\n",
      "Fold 2: Best Epoch = 80, Val_R² = 0.9706\n",
      "Fold 3: Early stopping at epoch 72 (patience=20)\n",
      "Fold 3: Best Epoch = 52, Val_R² = 0.9562\n",
      "Fold 4: Early stopping at epoch 76 (patience=20)\n",
      "Fold 4: Best Epoch = 56, Val_R² = 0.9437\n",
      "Fold 5: Early stopping at epoch 127 (patience=20)\n",
      "Fold 5: Best Epoch = 107, Val_R² = 0.9808\n",
      "Combination lr=0.005, patience=20, hidden_dim=32: Avg Val_R² = 0.9638, Avg Best Epoch = 74.00\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=20, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 65 (patience=20)\n",
      "Fold 1: Best Epoch = 45, Val_R² = 0.9667\n",
      "Fold 2: Early stopping at epoch 100 (patience=20)\n",
      "Fold 2: Best Epoch = 80, Val_R² = 0.9768\n",
      "Fold 3: Early stopping at epoch 90 (patience=20)\n",
      "Fold 3: Best Epoch = 70, Val_R² = 0.9578\n",
      "Fold 4: Early stopping at epoch 91 (patience=20)\n",
      "Fold 4: Best Epoch = 71, Val_R² = 0.9659\n",
      "Fold 5: Early stopping at epoch 85 (patience=20)\n",
      "Fold 5: Best Epoch = 65, Val_R² = 0.9804\n",
      "Combination lr=0.005, patience=20, hidden_dim=64: Avg Val_R² = 0.9695, Avg Best Epoch = 66.20\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=20, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 88 (patience=20)\n",
      "Fold 1: Best Epoch = 68, Val_R² = 0.9680\n",
      "Fold 2: Early stopping at epoch 100 (patience=20)\n",
      "Fold 2: Best Epoch = 80, Val_R² = 0.9732\n",
      "Fold 3: Early stopping at epoch 87 (patience=20)\n",
      "Fold 3: Best Epoch = 67, Val_R² = 0.9603\n",
      "Fold 4: Early stopping at epoch 75 (patience=20)\n",
      "Fold 4: Best Epoch = 55, Val_R² = 0.9630\n",
      "Fold 5: Early stopping at epoch 88 (patience=20)\n",
      "Fold 5: Best Epoch = 68, Val_R² = 0.9806\n",
      "Combination lr=0.005, patience=20, hidden_dim=128: Avg Val_R² = 0.9690, Avg Best Epoch = 67.60\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=30, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 85 (patience=30)\n",
      "Fold 1: Best Epoch = 55, Val_R² = 0.9639\n",
      "Fold 2: Early stopping at epoch 171 (patience=30)\n",
      "Fold 2: Best Epoch = 141, Val_R² = 0.9710\n",
      "Fold 3: Best Epoch = 200, Val_R² = 0.9665\n",
      "Fold 4: Early stopping at epoch 114 (patience=30)\n",
      "Fold 4: Best Epoch = 84, Val_R² = 0.9549\n",
      "Fold 5: Early stopping at epoch 116 (patience=30)\n",
      "Fold 5: Best Epoch = 86, Val_R² = 0.9812\n",
      "Combination lr=0.005, patience=30, hidden_dim=32: Avg Val_R² = 0.9675, Avg Best Epoch = 113.20\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=30, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 114 (patience=30)\n",
      "Fold 1: Best Epoch = 84, Val_R² = 0.9705\n",
      "Fold 2: Early stopping at epoch 114 (patience=30)\n",
      "Fold 2: Best Epoch = 84, Val_R² = 0.9758\n",
      "Fold 3: Early stopping at epoch 145 (patience=30)\n",
      "Fold 3: Best Epoch = 115, Val_R² = 0.9628\n",
      "Fold 4: Early stopping at epoch 113 (patience=30)\n",
      "Fold 4: Best Epoch = 83, Val_R² = 0.9608\n",
      "Fold 5: Early stopping at epoch 113 (patience=30)\n",
      "Fold 5: Best Epoch = 83, Val_R² = 0.9819\n",
      "Combination lr=0.005, patience=30, hidden_dim=64: Avg Val_R² = 0.9703, Avg Best Epoch = 89.80\n",
      "\n",
      "Testing combination: learning_rate=0.005, patience=30, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 80 (patience=30)\n",
      "Fold 1: Best Epoch = 50, Val_R² = 0.9685\n",
      "Fold 2: Early stopping at epoch 83 (patience=30)\n",
      "Fold 2: Best Epoch = 53, Val_R² = 0.9730\n",
      "Fold 3: Early stopping at epoch 105 (patience=30)\n",
      "Fold 3: Best Epoch = 75, Val_R² = 0.9629\n",
      "Fold 4: Early stopping at epoch 100 (patience=30)\n",
      "Fold 4: Best Epoch = 70, Val_R² = 0.9638\n",
      "Fold 5: Early stopping at epoch 93 (patience=30)\n",
      "Fold 5: Best Epoch = 63, Val_R² = 0.9824\n",
      "Combination lr=0.005, patience=30, hidden_dim=128: Avg Val_R² = 0.9701, Avg Best Epoch = 62.20\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=10, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 44 (patience=10)\n",
      "Fold 1: Best Epoch = 34, Val_R² = 0.9647\n",
      "Fold 2: Early stopping at epoch 57 (patience=10)\n",
      "Fold 2: Best Epoch = 47, Val_R² = 0.9754\n",
      "Fold 3: Early stopping at epoch 62 (patience=10)\n",
      "Fold 3: Best Epoch = 52, Val_R² = 0.9565\n",
      "Fold 4: Early stopping at epoch 70 (patience=10)\n",
      "Fold 4: Best Epoch = 60, Val_R² = 0.9650\n",
      "Fold 5: Early stopping at epoch 58 (patience=10)\n",
      "Fold 5: Best Epoch = 48, Val_R² = 0.9811\n",
      "Combination lr=0.01, patience=10, hidden_dim=32: Avg Val_R² = 0.9685, Avg Best Epoch = 48.20\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=10, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 55 (patience=10)\n",
      "Fold 1: Best Epoch = 45, Val_R² = 0.9683\n",
      "Fold 2: Early stopping at epoch 54 (patience=10)\n",
      "Fold 2: Best Epoch = 44, Val_R² = 0.9722\n",
      "Fold 3: Early stopping at epoch 99 (patience=10)\n",
      "Fold 3: Best Epoch = 89, Val_R² = 0.9578\n",
      "Fold 4: Early stopping at epoch 55 (patience=10)\n",
      "Fold 4: Best Epoch = 45, Val_R² = 0.9615\n",
      "Fold 5: Early stopping at epoch 63 (patience=10)\n",
      "Fold 5: Best Epoch = 53, Val_R² = 0.9796\n",
      "Combination lr=0.01, patience=10, hidden_dim=64: Avg Val_R² = 0.9679, Avg Best Epoch = 55.20\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=10, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 75 (patience=10)\n",
      "Fold 1: Best Epoch = 65, Val_R² = 0.9672\n",
      "Fold 2: Early stopping at epoch 55 (patience=10)\n",
      "Fold 2: Best Epoch = 45, Val_R² = 0.9656\n",
      "Fold 3: Early stopping at epoch 63 (patience=10)\n",
      "Fold 3: Best Epoch = 53, Val_R² = 0.9602\n",
      "Fold 4: Early stopping at epoch 102 (patience=10)\n",
      "Fold 4: Best Epoch = 92, Val_R² = 0.9615\n",
      "Fold 5: Early stopping at epoch 68 (patience=10)\n",
      "Fold 5: Best Epoch = 58, Val_R² = 0.9812\n",
      "Combination lr=0.01, patience=10, hidden_dim=128: Avg Val_R² = 0.9671, Avg Best Epoch = 62.60\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=20, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 98 (patience=20)\n",
      "Fold 1: Best Epoch = 78, Val_R² = 0.9670\n",
      "Fold 2: Early stopping at epoch 91 (patience=20)\n",
      "Fold 2: Best Epoch = 71, Val_R² = 0.9759\n",
      "Fold 3: Best Epoch = 197, Val_R² = 0.9633\n",
      "Fold 4: Early stopping at epoch 103 (patience=20)\n",
      "Fold 4: Best Epoch = 83, Val_R² = 0.9618\n",
      "Fold 5: Early stopping at epoch 114 (patience=20)\n",
      "Fold 5: Best Epoch = 94, Val_R² = 0.9819\n",
      "Combination lr=0.01, patience=20, hidden_dim=32: Avg Val_R² = 0.9700, Avg Best Epoch = 104.60\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=20, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 92 (patience=20)\n",
      "Fold 1: Best Epoch = 72, Val_R² = 0.9636\n",
      "Fold 2: Early stopping at epoch 108 (patience=20)\n",
      "Fold 2: Best Epoch = 88, Val_R² = 0.9741\n",
      "Fold 3: Early stopping at epoch 103 (patience=20)\n",
      "Fold 3: Best Epoch = 83, Val_R² = 0.9613\n",
      "Fold 4: Early stopping at epoch 58 (patience=20)\n",
      "Fold 4: Best Epoch = 38, Val_R² = 0.9489\n",
      "Fold 5: Early stopping at epoch 88 (patience=20)\n",
      "Fold 5: Best Epoch = 68, Val_R² = 0.9784\n",
      "Combination lr=0.01, patience=20, hidden_dim=64: Avg Val_R² = 0.9653, Avg Best Epoch = 69.80\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=20, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 82 (patience=20)\n",
      "Fold 1: Best Epoch = 62, Val_R² = 0.9657\n",
      "Fold 2: Early stopping at epoch 124 (patience=20)\n",
      "Fold 2: Best Epoch = 104, Val_R² = 0.9762\n",
      "Fold 3: Early stopping at epoch 94 (patience=20)\n",
      "Fold 3: Best Epoch = 74, Val_R² = 0.9637\n",
      "Fold 4: Early stopping at epoch 74 (patience=20)\n",
      "Fold 4: Best Epoch = 54, Val_R² = 0.9619\n",
      "Fold 5: Early stopping at epoch 111 (patience=20)\n",
      "Fold 5: Best Epoch = 91, Val_R² = 0.9807\n",
      "Combination lr=0.01, patience=20, hidden_dim=128: Avg Val_R² = 0.9696, Avg Best Epoch = 77.00\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=30, hidden_dim=32\n",
      "Fold 1: Early stopping at epoch 196 (patience=30)\n",
      "Fold 1: Best Epoch = 166, Val_R² = 0.9687\n",
      "Fold 2: Early stopping at epoch 100 (patience=30)\n",
      "Fold 2: Best Epoch = 70, Val_R² = 0.9762\n",
      "Fold 3: Best Epoch = 200, Val_R² = 0.9603\n",
      "Fold 4: Early stopping at epoch 98 (patience=30)\n",
      "Fold 4: Best Epoch = 68, Val_R² = 0.9659\n",
      "Fold 5: Early stopping at epoch 83 (patience=30)\n",
      "Fold 5: Best Epoch = 53, Val_R² = 0.9801\n",
      "Combination lr=0.01, patience=30, hidden_dim=32: Avg Val_R² = 0.9702, Avg Best Epoch = 111.40\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=30, hidden_dim=64\n",
      "Fold 1: Early stopping at epoch 84 (patience=30)\n",
      "Fold 1: Best Epoch = 54, Val_R² = 0.9681\n",
      "Fold 2: Early stopping at epoch 104 (patience=30)\n",
      "Fold 2: Best Epoch = 74, Val_R² = 0.9744\n",
      "Fold 3: Early stopping at epoch 78 (patience=30)\n",
      "Fold 3: Best Epoch = 48, Val_R² = 0.9651\n",
      "Fold 4: Early stopping at epoch 109 (patience=30)\n",
      "Fold 4: Best Epoch = 79, Val_R² = 0.9611\n",
      "Fold 5: Early stopping at epoch 77 (patience=30)\n",
      "Fold 5: Best Epoch = 47, Val_R² = 0.9826\n",
      "Combination lr=0.01, patience=30, hidden_dim=64: Avg Val_R² = 0.9703, Avg Best Epoch = 60.40\n",
      "\n",
      "Testing combination: learning_rate=0.01, patience=30, hidden_dim=128\n",
      "Fold 1: Early stopping at epoch 91 (patience=30)\n",
      "Fold 1: Best Epoch = 61, Val_R² = 0.9687\n",
      "Fold 2: Early stopping at epoch 117 (patience=30)\n",
      "Fold 2: Best Epoch = 87, Val_R² = 0.9752\n",
      "Fold 3: Early stopping at epoch 169 (patience=30)\n",
      "Fold 3: Best Epoch = 139, Val_R² = 0.9624\n",
      "Fold 4: Early stopping at epoch 130 (patience=30)\n",
      "Fold 4: Best Epoch = 100, Val_R² = 0.9638\n",
      "Fold 5: Early stopping at epoch 87 (patience=30)\n",
      "Fold 5: Best Epoch = 57, Val_R² = 0.9831\n",
      "Combination lr=0.01, patience=30, hidden_dim=128: Avg Val_R² = 0.9707, Avg Best Epoch = 88.80\n",
      "\n",
      "====== Grid Search Completed ======\n",
      "Best hyperparameters from grid search:\n",
      "{'learning_rate': 0.01, 'patience': 30, 'hidden_dim': 128, 'avg_val_r2': 0.9706638119157773, 'avg_best_epoch': 88.8}\n",
      "Final training epochs set to: 88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv,global_mean_pool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 种子固定\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)  # 设置 CPU 随机种子\n",
    "torch.cuda.manual_seed(42)  # 设置 GPU 随机种子\n",
    "torch.cuda.manual_seed_all(42)  # 如果使用多 GPU，设置所有 GPU 的随机种子\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------\n",
    "# 1. 环境及数据准备\n",
    "# -------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "file_path = '/kaggle/input/all-province/all_province_data.xlsx'  # 请根据实际路径修改\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# 将时间列转换为年份（假设 '时间' 列格式可提取数字）\n",
    "data['Year'] = data['时间'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# 独热编码省份\n",
    "data = pd.get_dummies(data, columns=['Province'])\n",
    "\n",
    "# 选择特征\n",
    "features = [\n",
    "    'Year', 'Ammonia Nitrogen Emissions', 'Average Temperature', \n",
    "    'Average Years of Education per Capita', 'Chemical Oxygen Demand Emissions', \n",
    "    'Electricity Consumption', 'Geographic-Mean PM2', \n",
    "    'Government Expenditure on Environmental Protection', \n",
    "    'NOx Emissions', 'Number of Healthcare Institutions', \n",
    "    'Number of Healthcare Personnel', 'Oil Emissions', \n",
    "    'Per Capita Disposable Income', 'Resident Population', \n",
    "    'SO2 Emissions', 'Total Nitrogen Emissions', \n",
    "    'Total Phosphorus Emissions'\n",
    "] + list(data.columns[data.columns.str.startswith('Province_')])\n",
    "\n",
    "X = data[features]\n",
    "y = data['Total CO2 emissions']\n",
    "\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# -------------------------\n",
    "# 2. 划分数据集\n",
    "# -------------------------\n",
    "# 将 2020, 2021, 2022 年的数据作为最终测试集，不参与交叉验证\n",
    "X_test_2020 = X[X['Year'] == 2020]\n",
    "X_test_2021 = X[X['Year'] == 2021]\n",
    "X_test_2022 = X[X['Year'] == 2022]\n",
    "\n",
    "y_test_2020 = y[X['Year'] == 2020]\n",
    "y_test_2021 = y[X['Year'] == 2021]\n",
    "y_test_2022 = y[X['Year'] == 2022]\n",
    "\n",
    "# 其他年份作为训练集进行交叉验证（例如：<=2019）\n",
    "X_train_all = X[~X['Year'].isin([2020, 2021, 2022])]\n",
    "y_train_all = y[~X['Year'].isin([2020, 2021, 2022])]\n",
    "\n",
    "# -------------------------\n",
    "# 3. 定义模型\n",
    "# -------------------------\n",
    "class GraphSAGEModel(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_dim, out_dim):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_node_features, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# 4. 定义构图函数\n",
    "# -------------------------\n",
    "def build_graph(x_array, threshold_percent=90):\n",
    "    \"\"\"\n",
    "    根据给定的特征数组构建图，使用欧氏距离与指定百分位阈值构图。\n",
    "    \"\"\"\n",
    "    distances = euclidean_distances(x_array)\n",
    "    threshold = np.percentile(distances, threshold_percent)\n",
    "    edge_index = np.array(np.where(distances < threshold))\n",
    "    # 去除自环\n",
    "    edge_index = edge_index[:, edge_index[0] != edge_index[1]]\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    x_tensor = torch.tensor(x_array, dtype=torch.float)\n",
    "    return Data(x=x_tensor, edge_index=edge_index)\n",
    "\n",
    "# -------------------------\n",
    "# 5. 五折交叉验证+早停+网格搜索\n",
    "# -------------------------\n",
    "candidate_learning_rates = [0.001, 0.005, 0.01]\n",
    "candidate_patience_values = [10, 20, 30]\n",
    "candidate_hidden_dims = [32, 64, 128]\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "grid_search_results = []\n",
    "\n",
    "print(\"\\n====== Begin Grid Search ======\")\n",
    "for lr in candidate_learning_rates:\n",
    "    for patience in candidate_patience_values:\n",
    "        for hidden_dim in candidate_hidden_dims:\n",
    "            fold_r2_scores = []\n",
    "            fold_best_epochs = []\n",
    "            print(f\"\\nTesting combination: learning_rate={lr}, patience={patience}, hidden_dim={hidden_dim}\")\n",
    "            for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_all)):\n",
    "                # 划分本折训练和验证数据\n",
    "                X_train_fold = X_train_all.iloc[train_idx].copy()\n",
    "                y_train_fold = y_train_all.iloc[train_idx].copy()\n",
    "                X_val_fold = X_train_all.iloc[val_idx].copy()\n",
    "                y_val_fold = y_train_all.iloc[val_idx].copy()\n",
    "                \n",
    "                scaler_x = MinMaxScaler()\n",
    "                X_train_fold_scaled = scaler_x.fit_transform(X_train_fold)\n",
    "                X_val_fold_scaled = scaler_x.transform(X_val_fold)\n",
    "                scaler_y = MinMaxScaler()\n",
    "                y_train_fold_scaled = scaler_y.fit_transform(y_train_fold.values.reshape(-1, 1)).ravel()\n",
    "                \n",
    "                train_data_fold = build_graph(X_train_fold_scaled).to(device)\n",
    "                val_data_fold = build_graph(X_val_fold_scaled).to(device)\n",
    "                y_train_fold_scaled_t = torch.tensor(y_train_fold_scaled, dtype=torch.float).to(device)\n",
    "                y_val_fold_t = torch.tensor(y_val_fold.values, dtype=torch.float).to(device)\n",
    "                \n",
    "                model = GraphSAGEModel(num_node_features=X_train_fold_scaled.shape[1],\n",
    "                                       hidden_dim=hidden_dim,\n",
    "                                       out_dim=1).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                criterion = torch.nn.MSELoss()\n",
    "                \n",
    "                best_val_r2 = float('-inf')\n",
    "                best_epoch = 0\n",
    "                no_improve_counter = 0\n",
    "                max_epochs = 200\n",
    "                \n",
    "                for epoch in range(max_epochs):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(train_data_fold).squeeze()\n",
    "                    loss = criterion(out, y_train_fold_scaled_t)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # 验证\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        preds_val = model(val_data_fold).squeeze().cpu().numpy()\n",
    "                    preds_val_unscaled = scaler_y.inverse_transform(preds_val.reshape(-1, 1)).ravel()\n",
    "                    val_r2 = r2_score(y_val_fold_t.cpu().numpy(), preds_val_unscaled)\n",
    "                    \n",
    "                    if val_r2 > best_val_r2:\n",
    "                        best_val_r2 = val_r2\n",
    "                        best_epoch = epoch + 1\n",
    "                        no_improve_counter = 0\n",
    "                    else:\n",
    "                        no_improve_counter += 1\n",
    "                    if no_improve_counter >= patience:\n",
    "                        print(f\"Fold {fold+1}: Early stopping at epoch {epoch+1} (patience={patience})\")\n",
    "                        break\n",
    "                fold_r2_scores.append(best_val_r2)\n",
    "                fold_best_epochs.append(best_epoch)\n",
    "                print(f\"Fold {fold+1}: Best Epoch = {best_epoch}, Val_R² = {best_val_r2:.4f}\")\n",
    "            \n",
    "            avg_r2 = np.mean(fold_r2_scores)\n",
    "            avg_best_epoch = np.mean(fold_best_epochs)\n",
    "            print(f\"Combination lr={lr}, patience={patience}, hidden_dim={hidden_dim}: Avg Val_R² = {avg_r2:.4f}, Avg Best Epoch = {avg_best_epoch:.2f}\")\n",
    "            grid_search_results.append({\n",
    "                'learning_rate': lr,\n",
    "                'patience': patience,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'avg_val_r2': avg_r2,\n",
    "                'avg_best_epoch': avg_best_epoch\n",
    "            })\n",
    "\n",
    "# 选择最佳超参数组合\n",
    "best_combo = max(grid_search_results, key=lambda x: x['avg_val_r2'])\n",
    "best_learning_rate = best_combo['learning_rate']\n",
    "best_patience = best_combo['patience']\n",
    "best_hidden_dim = best_combo['hidden_dim']\n",
    "final_num_epochs = int(best_combo['avg_best_epoch'])  # 使用平均 best epoch 作为最终训练轮次\n",
    "\n",
    "print(\"\\n====== Grid Search Completed ======\")\n",
    "print(\"Best hyperparameters from grid search:\")\n",
    "print(best_combo)\n",
    "print(f\"Final training epochs set to: {final_num_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0a680e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T09:49:18.987626Z",
     "iopub.status.busy": "2025-03-10T09:49:18.987148Z",
     "iopub.status.idle": "2025-03-10T09:49:21.158374Z",
     "shell.execute_reply": "2025-03-10T09:49:21.157518Z"
    },
    "papermill": {
     "duration": 2.181497,
     "end_time": "2025-03-10T09:49:21.159647",
     "exception": false,
     "start_time": "2025-03-10T09:49:18.978150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Begin Final Training with Best Hyperparameters ======\n",
      "\n",
      "Final Training run 1/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0015\n",
      "Run 1: Training Time = 0.22 s\n",
      "2020 - RMSE: 2670.8430, MAE: 2163.3206, R²: 0.9684, NMAE: 0.0601, NRMSE: 0.0742\n",
      "2021 - RMSE: 3128.9417, MAE: 2631.5212, R²: 0.9595, NMAE: 0.0716, NRMSE: 0.0852\n",
      "2022 - RMSE: 3123.2458, MAE: 2641.5251, R²: 0.9559, NMAE: 0.0718, NRMSE: 0.0849\n",
      "\n",
      "Final Training run 2/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0017\n",
      "Run 2: Training Time = 0.22 s\n",
      "2020 - RMSE: 2767.6313, MAE: 2345.6641, R²: 0.9661, NMAE: 0.0651, NRMSE: 0.0769\n",
      "2021 - RMSE: 3262.3987, MAE: 2783.6306, R²: 0.9559, NMAE: 0.0758, NRMSE: 0.0888\n",
      "2022 - RMSE: 2786.8828, MAE: 2159.6018, R²: 0.9649, NMAE: 0.0587, NRMSE: 0.0758\n",
      "\n",
      "Final Training run 3/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0018\n",
      "Run 3: Training Time = 0.21 s\n",
      "2020 - RMSE: 2881.1753, MAE: 2438.5386, R²: 0.9632, NMAE: 0.0677, NRMSE: 0.0800\n",
      "2021 - RMSE: 3188.2766, MAE: 2738.1638, R²: 0.9579, NMAE: 0.0745, NRMSE: 0.0868\n",
      "2022 - RMSE: 2759.3784, MAE: 2245.3315, R²: 0.9656, NMAE: 0.0611, NRMSE: 0.0750\n",
      "\n",
      "Final Training run 4/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0020\n",
      "Run 4: Training Time = 0.21 s\n",
      "2020 - RMSE: 2511.6995, MAE: 2058.2493, R²: 0.9720, NMAE: 0.0572, NRMSE: 0.0698\n",
      "2021 - RMSE: 2984.2539, MAE: 2523.1416, R²: 0.9631, NMAE: 0.0687, NRMSE: 0.0812\n",
      "2022 - RMSE: 2965.1636, MAE: 2699.5110, R²: 0.9603, NMAE: 0.0734, NRMSE: 0.0806\n",
      "\n",
      "Final Training run 5/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0015\n",
      "Run 5: Training Time = 0.21 s\n",
      "2020 - RMSE: 2684.4851, MAE: 2173.8276, R²: 0.9681, NMAE: 0.0604, NRMSE: 0.0746\n",
      "2021 - RMSE: 3312.6609, MAE: 2608.0103, R²: 0.9546, NMAE: 0.0710, NRMSE: 0.0902\n",
      "2022 - RMSE: 3695.1599, MAE: 3117.8738, R²: 0.9383, NMAE: 0.0848, NRMSE: 0.1005\n",
      "\n",
      "Final Training run 6/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0020\n",
      "Run 6: Training Time = 0.21 s\n",
      "2020 - RMSE: 3574.9482, MAE: 2873.8816, R²: 0.9434, NMAE: 0.0798, NRMSE: 0.0993\n",
      "2021 - RMSE: 4556.9473, MAE: 3689.8604, R²: 0.9141, NMAE: 0.1004, NRMSE: 0.1240\n",
      "2022 - RMSE: 5405.3130, MAE: 4781.0698, R²: 0.8681, NMAE: 0.1300, NRMSE: 0.1470\n",
      "\n",
      "Final Training run 7/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0015\n",
      "Run 7: Training Time = 0.22 s\n",
      "2020 - RMSE: 2748.5569, MAE: 2358.6709, R²: 0.9665, NMAE: 0.0655, NRMSE: 0.0763\n",
      "2021 - RMSE: 3133.3867, MAE: 2748.0386, R²: 0.9594, NMAE: 0.0748, NRMSE: 0.0853\n",
      "2022 - RMSE: 2575.6997, MAE: 2207.7087, R²: 0.9700, NMAE: 0.0600, NRMSE: 0.0700\n",
      "\n",
      "Final Training run 8/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0019\n",
      "Run 8: Training Time = 0.21 s\n",
      "2020 - RMSE: 2613.3411, MAE: 2166.4248, R²: 0.9697, NMAE: 0.0602, NRMSE: 0.0726\n",
      "2021 - RMSE: 3107.3892, MAE: 2716.2036, R²: 0.9600, NMAE: 0.0739, NRMSE: 0.0846\n",
      "2022 - RMSE: 2740.1399, MAE: 2295.4351, R²: 0.9661, NMAE: 0.0624, NRMSE: 0.0745\n",
      "\n",
      "Final Training run 9/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0015\n",
      "Run 9: Training Time = 0.21 s\n",
      "2020 - RMSE: 2357.0103, MAE: 1851.4117, R²: 0.9754, NMAE: 0.0514, NRMSE: 0.0655\n",
      "2021 - RMSE: 3053.7417, MAE: 2521.7666, R²: 0.9614, NMAE: 0.0686, NRMSE: 0.0831\n",
      "2022 - RMSE: 2902.6494, MAE: 2515.0535, R²: 0.9620, NMAE: 0.0684, NRMSE: 0.0789\n",
      "\n",
      "Final Training run 10/10\n",
      "[Final Train] Epoch 50/88, Loss: 0.0014\n",
      "Run 10: Training Time = 0.21 s\n",
      "2020 - RMSE: 2851.5911, MAE: 2420.9565, R²: 0.9640, NMAE: 0.0672, NRMSE: 0.0792\n",
      "2021 - RMSE: 3426.3977, MAE: 2987.4519, R²: 0.9514, NMAE: 0.0813, NRMSE: 0.0933\n",
      "2022 - RMSE: 3052.0542, MAE: 2459.7009, R²: 0.9579, NMAE: 0.0669, NRMSE: 0.0830\n",
      "\n",
      "Results saved to 'model_training_results_with_time.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# 种子固定\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)  # 设置 CPU 随机种子\n",
    "torch.cuda.manual_seed(42)  # 设置 GPU 随机种子\n",
    "torch.cuda.manual_seed_all(42)  # 如果使用多 GPU，设置所有 GPU 的随机种子\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -------------------------\n",
    "# 7. 可选：使用最佳超参数以及数据训练最终模型，并对 2020-2022 预测\n",
    "# -------------------------\n",
    "# 对所有训练数据重新标准化\n",
    "scaler_x_final = MinMaxScaler()\n",
    "X_train_all_scaled = scaler_x_final.fit_transform(X_train_all)\n",
    "scaler_y_final = MinMaxScaler()\n",
    "y_train_all_scaled = scaler_y_final.fit_transform(y_train_all.values.reshape(-1, 1)).ravel()\n",
    "train_data_final = build_graph(X_train_all_scaled).to(device)\n",
    "y_train_all_scaled_t = torch.tensor(y_train_all_scaled, dtype=torch.float).to(device)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n====== Begin Final Training with Best Hyperparameters ======\")\n",
    "for i in range(10):\n",
    "    print(f\"\\nFinal Training run {i+1}/10\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_final = GraphSAGEModel(num_node_features=X_train_all_scaled.shape[1],\n",
    "                                 hidden_dim=best_hidden_dim,\n",
    "                                 out_dim=1).to(device)\n",
    "    optimizer_final = torch.optim.Adam(model_final.parameters(), lr=best_learning_rate)\n",
    "    criterion_final = torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(final_num_epochs):\n",
    "        model_final.train()\n",
    "        optimizer_final.zero_grad()\n",
    "        out_final = model_final(train_data_final).squeeze()\n",
    "        loss_final = criterion_final(out_final, y_train_all_scaled_t)\n",
    "        loss_final.backward()\n",
    "        optimizer_final.step()\n",
    "        \n",
    "        if (epoch+1) % 50 == 0:\n",
    "            print(f\"[Final Train] Epoch {epoch+1}/{final_num_epochs}, Loss: {loss_final.item():.4f}\")\n",
    "    \n",
    "    model_filename = f'final_model_run_{i+1}.pth'\n",
    "    torch.save(model_final.state_dict(), model_filename)\n",
    "    \n",
    "    def predict_and_evaluate(model, X_test, y_test):\n",
    "        X_test_scaled = scaler_x_final.transform(X_test)\n",
    "        data_test = build_graph(X_test_scaled).to(device)\n",
    "        y_test_t = torch.tensor(y_test.values, dtype=torch.float).to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds_test = model(data_test).squeeze().cpu().numpy()\n",
    "        preds_test_unscaled = scaler_y_final.inverse_transform(preds_test.reshape(-1, 1)).ravel()\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_t.cpu().numpy(), preds_test_unscaled))\n",
    "        mae = mean_absolute_error(y_test_t.cpu().numpy(), preds_test_unscaled)\n",
    "        r2 = r2_score(y_test_t.cpu().numpy(), preds_test_unscaled)\n",
    "        nmae = mae / np.mean(y_test_t.cpu().numpy()) if np.mean(y_test_t.cpu().numpy()) != 0 else np.nan\n",
    "        nrmse = rmse / np.mean(y_test_t.cpu().numpy()) if np.mean(y_test_t.cpu().numpy()) != 0 else np.nan\n",
    "        return rmse, mae, r2, nmae, nrmse\n",
    "    \n",
    "    rmse_2020, mae_2020, r2_2020, nmae_2020, nrmse_2020 = predict_and_evaluate(model_final, X_test_2020, y_test_2020)\n",
    "    rmse_2021, mae_2021, r2_2021, nmae_2021, nrmse_2021 = predict_and_evaluate(model_final, X_test_2021, y_test_2021)\n",
    "    rmse_2022, mae_2022, r2_2022, nmae_2022, nrmse_2022 = predict_and_evaluate(model_final, X_test_2022, y_test_2022)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Run {i+1}: Training Time = {training_time:.2f} s\")\n",
    "    print(f\"2020 - RMSE: {rmse_2020:.4f}, MAE: {mae_2020:.4f}, R²: {r2_2020:.4f}, NMAE: {nmae_2020:.4f}, NRMSE: {nrmse_2020:.4f}\")\n",
    "    print(f\"2021 - RMSE: {rmse_2021:.4f}, MAE: {mae_2021:.4f}, R²: {r2_2021:.4f}, NMAE: {nmae_2021:.4f}, NRMSE: {nrmse_2021:.4f}\")\n",
    "    print(f\"2022 - RMSE: {rmse_2022:.4f}, MAE: {mae_2022:.4f}, R²: {r2_2022:.4f}, NMAE: {nmae_2022:.4f}, NRMSE: {nrmse_2022:.4f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'Run': i+1,\n",
    "        'Training_Time (s)': training_time,\n",
    "        'RMSE_2020': rmse_2020, 'MAE_2020': mae_2020, 'R²_2020': r2_2020, 'NMAE_2020': nmae_2020, 'NRMSE_2020': nrmse_2020,\n",
    "        'RMSE_2021': rmse_2021, 'MAE_2021': mae_2021, 'R²_2021': r2_2021, 'NMAE_2021': nmae_2021, 'NRMSE_2021': nrmse_2021,\n",
    "        'RMSE_2022': rmse_2022, 'MAE_2022': mae_2022, 'R²_2022': r2_2022, 'NMAE_2022': nmae_2022, 'NRMSE_2022': nrmse_2022\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('model_training_results_with_time.csv', index=False)\n",
    "print(\"\\nResults saved to 'model_training_results_with_time.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5686780,
     "sourceId": 9375395,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 80.252024,
   "end_time": "2025-03-10T09:49:22.889417",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-10T09:48:02.637393",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
