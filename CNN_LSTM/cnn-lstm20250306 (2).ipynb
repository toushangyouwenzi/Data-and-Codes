{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7434f8b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-18T04:20:26.517196Z",
     "iopub.status.busy": "2025-03-18T04:20:26.516926Z",
     "iopub.status.idle": "2025-03-18T04:20:27.227958Z",
     "shell.execute_reply": "2025-03-18T04:20:27.226965Z"
    },
    "papermill": {
     "duration": 0.715455,
     "end_time": "2025-03-18T04:20:27.229460",
     "exception": false,
     "start_time": "2025-03-18T04:20:26.514005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/all-province/all_province_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d90a703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T04:20:27.234231Z",
     "iopub.status.busy": "2025-03-18T04:20:27.233901Z",
     "iopub.status.idle": "2025-03-18T04:29:04.593048Z",
     "shell.execute_reply": "2025-03-18T04:29:04.591966Z"
    },
    "papermill": {
     "duration": 517.363005,
     "end_time": "2025-03-18T04:29:04.594533",
     "exception": false,
     "start_time": "2025-03-18T04:20:27.231528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "====== Begin CNN_LSTM Grid Search ======\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 32, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 425 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 660 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 156 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 891 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.7435\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 32, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 680 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "  Fold 4 - Training...\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 879 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.9060\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 32, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "  Fold 2 - Training...\n",
      "  Fold 3 - Training...\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 901 (patience=150)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 616 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9256\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 64, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 608 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 454 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 635 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 121 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 283 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.7537\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 64, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 642 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 589 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 761 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 603 (patience=100)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 532 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.9146\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 64, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 743 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 816 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 683 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 660 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9342\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 128, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 481 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 219 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 477 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 486 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 493 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.8844\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 128, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 418 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 481 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 698 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 793 (patience=100)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 349 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.8936\n",
      "\n",
      "Testing Learning Rate: 0.001, Hidden Dim: 128, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 960 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 533 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 690 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 726 (patience=150)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 572 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9462\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 32, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 388 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 390 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 378 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 246 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 406 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.8581\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 32, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 654 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 450 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 427 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 320 (patience=100)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 580 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.8738\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 32, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 854 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 655 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 482 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 989 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9452\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 64, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 323 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 271 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 220 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 589 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 372 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.8422\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 64, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 444 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 596 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 583 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 400 (patience=100)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 401 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.9419\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 64, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 640 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 653 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 370 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 574 (patience=150)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 516 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9461\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 128, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 224 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 249 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 138 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 276 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 468 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.7526\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 128, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 580 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 514 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 439 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 767 (patience=100)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 382 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.9265\n",
      "\n",
      "Testing Learning Rate: 0.005, Hidden Dim: 128, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 541 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 428 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 415 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 688 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9411\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 32, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 369 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 432 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 172 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 101 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 352 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.7559\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 32, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 179 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 497 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 520 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 289 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.7657\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 32, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 691 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 456 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 867 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 534 (patience=150)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 793 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9167\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 64, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 274 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 280 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 314 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 306 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 348 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.9174\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 64, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 543 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 569 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 548 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 356 (patience=100)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 283 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.7655\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 64, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 544 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 469 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 674 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 759 (patience=150)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 558 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9129\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 128, Patience: 50\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 444 (patience=50)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 228 (patience=50)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 159 (patience=50)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 447 (patience=50)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 215 (patience=50)\n",
      "Avg R² for this set of hyperparameters: 0.8710\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 128, Patience: 100\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 217 (patience=100)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 371 (patience=100)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 340 (patience=100)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 409 (patience=100)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 400 (patience=100)\n",
      "Avg R² for this set of hyperparameters: 0.8960\n",
      "\n",
      "Testing Learning Rate: 0.01, Hidden Dim: 128, Patience: 150\n",
      "  Fold 1 - Training...\n",
      "    Fold 1: Early stopping at epoch 448 (patience=150)\n",
      "  Fold 2 - Training...\n",
      "    Fold 2: Early stopping at epoch 573 (patience=150)\n",
      "  Fold 3 - Training...\n",
      "    Fold 3: Early stopping at epoch 692 (patience=150)\n",
      "  Fold 4 - Training...\n",
      "    Fold 4: Early stopping at epoch 964 (patience=150)\n",
      "  Fold 5 - Training...\n",
      "    Fold 5: Early stopping at epoch 759 (patience=150)\n",
      "Avg R² for this set of hyperparameters: 0.9271\n",
      "\n",
      "====== CNN_LSTM Grid Search Completed ======\n",
      "Best Hyperparameters: Learning Rate = 0.001, Hidden Dim = 128, Epochs = 546\n",
      "\n",
      "====== Training CNN_LSTM Run 1/10 ======\n",
      "Model 1 saved as final_CNN_LSTM_model_run_1.pth\n",
      "Run 1: Training Time = 6.77 s\n",
      "2020 - RMSE: 5579.6454, MAE: 4243.0283, R²: 0.8621, NMAE: 0.1178, NRMSE: 0.1550\n",
      "2021 - RMSE: 7510.9355, MAE: 5261.6142, R²: 0.7665, NMAE: 0.1432, NRMSE: 0.2044\n",
      "2022 - RMSE: 7959.5724, MAE: 6125.9066, R²: 0.7139, NMAE: 0.1666, NRMSE: 0.2164\n",
      "\n",
      "====== Training CNN_LSTM Run 2/10 ======\n",
      "Model 2 saved as final_CNN_LSTM_model_run_2.pth\n",
      "Run 2: Training Time = 6.76 s\n",
      "2020 - RMSE: 5255.7109, MAE: 4068.1656, R²: 0.8776, NMAE: 0.1130, NRMSE: 0.1460\n",
      "2021 - RMSE: 6068.0847, MAE: 5070.5514, R²: 0.8476, NMAE: 0.1380, NRMSE: 0.1652\n",
      "2022 - RMSE: 5921.1167, MAE: 4516.3160, R²: 0.8417, NMAE: 0.1228, NRMSE: 0.1610\n",
      "\n",
      "====== Training CNN_LSTM Run 3/10 ======\n",
      "Model 3 saved as final_CNN_LSTM_model_run_3.pth\n",
      "Run 3: Training Time = 6.75 s\n",
      "2020 - RMSE: 9330.0595, MAE: 6472.3343, R²: 0.6143, NMAE: 0.1798, NRMSE: 0.2591\n",
      "2021 - RMSE: 9324.6830, MAE: 6703.6550, R²: 0.6401, NMAE: 0.1825, NRMSE: 0.2538\n",
      "2022 - RMSE: 7801.1045, MAE: 5761.0100, R²: 0.7252, NMAE: 0.1566, NRMSE: 0.2121\n",
      "\n",
      "====== Training CNN_LSTM Run 4/10 ======\n",
      "Model 4 saved as final_CNN_LSTM_model_run_4.pth\n",
      "Run 4: Training Time = 6.77 s\n",
      "2020 - RMSE: 5265.5783, MAE: 3873.9037, R²: 0.8771, NMAE: 0.1076, NRMSE: 0.1462\n",
      "2021 - RMSE: 7741.7388, MAE: 4884.2389, R²: 0.7519, NMAE: 0.1329, NRMSE: 0.2107\n",
      "2022 - RMSE: 7929.4115, MAE: 4966.1229, R²: 0.7161, NMAE: 0.1350, NRMSE: 0.2156\n",
      "\n",
      "====== Training CNN_LSTM Run 5/10 ======\n",
      "Model 5 saved as final_CNN_LSTM_model_run_5.pth\n",
      "Run 5: Training Time = 6.76 s\n",
      "2020 - RMSE: 4906.5723, MAE: 3851.6992, R²: 0.8933, NMAE: 0.1070, NRMSE: 0.1363\n",
      "2021 - RMSE: 6277.5673, MAE: 4504.4060, R²: 0.8369, NMAE: 0.1226, NRMSE: 0.1709\n",
      "2022 - RMSE: 5614.9064, MAE: 4366.9051, R²: 0.8576, NMAE: 0.1187, NRMSE: 0.1527\n",
      "\n",
      "====== Training CNN_LSTM Run 6/10 ======\n",
      "Model 6 saved as final_CNN_LSTM_model_run_6.pth\n",
      "Run 6: Training Time = 6.79 s\n",
      "2020 - RMSE: 6051.3523, MAE: 4347.5673, R²: 0.8377, NMAE: 0.1207, NRMSE: 0.1681\n",
      "2021 - RMSE: 6091.9613, MAE: 4641.5227, R²: 0.8464, NMAE: 0.1263, NRMSE: 0.1658\n",
      "2022 - RMSE: 5110.2534, MAE: 3831.2050, R²: 0.8821, NMAE: 0.1042, NRMSE: 0.1390\n",
      "\n",
      "====== Training CNN_LSTM Run 7/10 ======\n",
      "Model 7 saved as final_CNN_LSTM_model_run_7.pth\n",
      "Run 7: Training Time = 6.77 s\n",
      "2020 - RMSE: 6578.7369, MAE: 5169.7264, R²: 0.8082, NMAE: 0.1436, NRMSE: 0.1827\n",
      "2021 - RMSE: 9073.7901, MAE: 6886.9890, R²: 0.6592, NMAE: 0.1875, NRMSE: 0.2470\n",
      "2022 - RMSE: 8580.9157, MAE: 6605.8403, R²: 0.6675, NMAE: 0.1796, NRMSE: 0.2333\n",
      "\n",
      "====== Training CNN_LSTM Run 8/10 ======\n",
      "Model 8 saved as final_CNN_LSTM_model_run_8.pth\n",
      "Run 8: Training Time = 6.79 s\n",
      "2020 - RMSE: 5352.5343, MAE: 3877.8897, R²: 0.8731, NMAE: 0.1077, NRMSE: 0.1487\n",
      "2021 - RMSE: 6062.5524, MAE: 4752.1579, R²: 0.8479, NMAE: 0.1293, NRMSE: 0.1650\n",
      "2022 - RMSE: 6520.7738, MAE: 4997.5058, R²: 0.8080, NMAE: 0.1359, NRMSE: 0.1773\n",
      "\n",
      "====== Training CNN_LSTM Run 9/10 ======\n",
      "Model 9 saved as final_CNN_LSTM_model_run_9.pth\n",
      "Run 9: Training Time = 6.77 s\n",
      "2020 - RMSE: 5093.4796, MAE: 3793.3397, R²: 0.8850, NMAE: 0.1054, NRMSE: 0.1415\n",
      "2021 - RMSE: 6852.1744, MAE: 5266.7274, R²: 0.8057, NMAE: 0.1434, NRMSE: 0.1865\n",
      "2022 - RMSE: 6996.2338, MAE: 5198.8978, R²: 0.7790, NMAE: 0.1414, NRMSE: 0.1902\n",
      "\n",
      "====== Training CNN_LSTM Run 10/10 ======\n",
      "Model 10 saved as final_CNN_LSTM_model_run_10.pth\n",
      "Run 10: Training Time = 6.79 s\n",
      "2020 - RMSE: 6702.7645, MAE: 4738.2563, R²: 0.8009, NMAE: 0.1316, NRMSE: 0.1862\n",
      "2021 - RMSE: 9633.4623, MAE: 7309.1080, R²: 0.6159, NMAE: 0.1989, NRMSE: 0.2622\n",
      "2022 - RMSE: 11078.2072, MAE: 8087.3450, R²: 0.4458, NMAE: 0.2199, NRMSE: 0.3012\n",
      "Results saved to CNN_LSTM_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "# 种子固定\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)  # 设置 CPU 随机种子\n",
    "torch.cuda.manual_seed(42)  # 设置 GPU 随机种子\n",
    "torch.cuda.manual_seed_all(42)  # 如果使用多 GPU，设置所有 GPU 的随机种子\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# ===============================\n",
    "# 1. 数据预处理\n",
    "# ===============================\n",
    "file_path = '/kaggle/input/all-province/all_province_data.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "data['Year'] = data['时间'].str.extract('(\\d+)').astype(int)\n",
    "data = pd.get_dummies(data, columns=['Province'])\n",
    "\n",
    "# 选择特征\n",
    "features = [\n",
    "    'Year', 'Ammonia Nitrogen Emissions', 'Average Temperature',\n",
    "    'Average Years of Education per Capita', 'Chemical Oxygen Demand Emissions',\n",
    "    'Electricity Consumption', 'Geographic-Mean PM2',\n",
    "    'Government Expenditure on Environmental Protection',\n",
    "    'NOx Emissions', 'Number of Healthcare Institutions',\n",
    "    'Number of Healthcare Personnel', 'Oil Emissions',\n",
    "    'Per Capita Disposable Income', 'Resident Population',\n",
    "    'SO2 Emissions', 'Total Nitrogen Emissions',\n",
    "    'Total Phosphorus Emissions'\n",
    "] + list(data.columns[data.columns.str.startswith('Province_')])\n",
    "\n",
    "X = data[features]\n",
    "y = data['Total CO2 emissions']\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_test_2020 = X[X['Year'] == 2020]\n",
    "X_test_2021 = X[X['Year'] == 2021]\n",
    "X_test_2022 = X[X['Year'] == 2022]\n",
    "y_test_2020 = y[X['Year'] == 2020]\n",
    "y_test_2021 = y[X['Year'] == 2021]\n",
    "y_test_2022 = y[X['Year'] == 2022]\n",
    "X_train_all = X[~X['Year'].isin([2020, 2021, 2022])]\n",
    "y_train_all = y[~X['Year'].isin([2020, 2021, 2022])]\n",
    "\n",
    "# 标准化数据\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_all_scaled = scaler_x.fit_transform(X_train_all)\n",
    "X_test_2020_scaled = scaler_x.transform(X_test_2020)\n",
    "X_test_2021_scaled = scaler_x.transform(X_test_2021)\n",
    "X_test_2022_scaled = scaler_x.transform(X_test_2022)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_all_scaled = scaler_y.fit_transform(y_train_all.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# ===============================\n",
    "# 2. 定义 CNN_LSTM 模型\n",
    "# ===============================\n",
    "class CNN_LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(CNN_LSTMModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, num_features)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.permute(0, 2, 1)  # 调整维度以适应 LSTM 输入 (batch_size, sequence_length, hidden_dim)\n",
    "        out, _ = self.lstm(x)\n",
    "        x = self.fc(out[:, -1, :])  # 取最后一个时间步的输出\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 3. 五折交叉验证 (超参数选择)\n",
    "# ===============================\n",
    "candidate_learning_rates = [0.001, 0.005, 0.01]\n",
    "candidate_hidden_dims = [32, 64, 128]\n",
    "candidate_patience_values = [50, 100, 150]\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "best_hyperparams = None\n",
    "best_avg_r2 = float('-inf')\n",
    "\n",
    "print(\"\\n====== Begin CNN_LSTM Grid Search ======\")\n",
    "for lr in candidate_learning_rates:\n",
    "    for hidden_dim in candidate_hidden_dims:\n",
    "        for patience in candidate_patience_values:\n",
    "            print(f\"\\nTesting Learning Rate: {lr}, Hidden Dim: {hidden_dim}, Patience: {patience}\")\n",
    "            fold_r2_scores = []\n",
    "            fold_best_epochs = []\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_all_scaled), 1):\n",
    "                print(f\"  Fold {fold} - Training...\")\n",
    "\n",
    "                X_train_fold, X_val_fold = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "                y_train_fold, y_val_fold = y_train_all_scaled[train_idx], y_train_all_scaled[val_idx]\n",
    "\n",
    "                X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32).to(device)\n",
    "                y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32).to(device)\n",
    "                X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32).to(device)\n",
    "                y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32).to(device)\n",
    "\n",
    "                model = CNN_LSTMModel(X_train_all.shape[1], hidden_dim, 1).to(device)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                criterion = nn.MSELoss()\n",
    "\n",
    "                best_val_r2 = float('-inf')\n",
    "                best_epoch = 0\n",
    "                no_improve_counter = 0\n",
    "                max_epochs = 1000\n",
    "\n",
    "                for epoch in range(max_epochs):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    predictions = model(X_train_tensor).squeeze()\n",
    "                    loss = criterion(predictions, y_train_tensor)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        preds_val = model(X_val_tensor).squeeze().cpu().numpy()\n",
    "                    val_r2 = r2_score(y_val_tensor.cpu().numpy(), preds_val)\n",
    "\n",
    "                    if val_r2 > best_val_r2:\n",
    "                        best_val_r2 = val_r2\n",
    "                        best_epoch = epoch + 1\n",
    "                        no_improve_counter = 0\n",
    "                    else:\n",
    "                        no_improve_counter += 1\n",
    "                    if no_improve_counter >= patience:\n",
    "                        print(f\"    Fold {fold}: Early stopping at epoch {epoch+1} (patience={patience})\")\n",
    "                        break\n",
    "\n",
    "                fold_r2_scores.append(best_val_r2)\n",
    "                fold_best_epochs.append(best_epoch)\n",
    "\n",
    "            avg_r2 = np.mean(fold_r2_scores)\n",
    "            avg_best_epoch = np.mean(fold_best_epochs)\n",
    "\n",
    "            print(f\"Avg R² for this set of hyperparameters: {avg_r2:.4f}\")\n",
    "\n",
    "            if avg_r2 > best_avg_r2:\n",
    "                best_avg_r2 = avg_r2\n",
    "                best_hyperparams = (lr, hidden_dim, avg_best_epoch)\n",
    "\n",
    "print(\"\\n====== CNN_LSTM Grid Search Completed ======\")\n",
    "best_learning_rate, best_hidden_dim, final_num_epochs = best_hyperparams\n",
    "print(f\"Best Hyperparameters: Learning Rate = {best_learning_rate}, Hidden Dim = {best_hidden_dim}, Epochs = {int(final_num_epochs)}\")\n",
    "\n",
    "# ===============================\n",
    "# 4. 计算 RMSE、MAE、R²、NMAE、NRMSE\n",
    "# ===============================\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    X_test_scaled = scaler_x.transform(X_test)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_test = model(X_test_tensor).squeeze().cpu().numpy()\n",
    "    preds_test_unscaled = scaler_y.inverse_transform(preds_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds_test_unscaled))\n",
    "    mae = mean_absolute_error(y_test, preds_test_unscaled)\n",
    "    r2 = r2_score(y_test, preds_test_unscaled)\n",
    "    nmae = mae / np.mean(y_test) if np.mean(y_test) != 0 else np.nan\n",
    "    nrmse = rmse / np.mean(y_test) if np.mean(y_test) != 0 else np.nan\n",
    "\n",
    "    return rmse, mae, r2, nmae, nrmse\n",
    "\n",
    "# ===============================\n",
    "# 5. 10 次训练，保存结果\n",
    "# ===============================\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"\\n====== Training CNN_LSTM Run {i+1}/10 ======\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 初始化 CNN_LSTM 模型\n",
    "    model = CNN_LSTMModel(X_train_all.shape[1], best_hidden_dim, 1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(int(final_num_epochs)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(torch.tensor(X_train_all_scaled, dtype=torch.float32).to(device)).squeeze()\n",
    "        loss = criterion(predictions, torch.tensor(y_train_all_scaled, dtype=torch.float32).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 计算训练时间\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # 保存模型\n",
    "    model_filename = f'final_CNN_LSTM_model_run_{i+1}.pth'\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print(f\"Model {i+1} saved as {model_filename}\")\n",
    "\n",
    "    # 评估模型在 2020、2021、2022 上的表现\n",
    "    rmse_2020, mae_2020, r2_2020, nmae_2020, nrmse_2020 = evaluate_model(model, X_test_2020, y_test_2020)\n",
    "    rmse_2021, mae_2021, r2_2021, nmae_2021, nrmse_2021 = evaluate_model(model, X_test_2021, y_test_2021)\n",
    "    rmse_2022, mae_2022, r2_2022, nmae_2022, nrmse_2022 = evaluate_model(model, X_test_2022, y_test_2022)\n",
    "\n",
    "    print(f\"Run {i+1}: Training Time = {training_time:.2f} s\")\n",
    "    print(f\"2020 - RMSE: {rmse_2020:.4f}, MAE: {mae_2020:.4f}, R²: {r2_2020:.4f}, NMAE: {nmae_2020:.4f}, NRMSE: {nrmse_2020:.4f}\")\n",
    "    print(f\"2021 - RMSE: {rmse_2021:.4f}, MAE: {mae_2021:.4f}, R²: {r2_2021:.4f}, NMAE: {nmae_2021:.4f}, NRMSE: {nrmse_2021:.4f}\")\n",
    "    print(f\"2022 - RMSE: {rmse_2022:.4f}, MAE: {mae_2022:.4f}, R²: {r2_2022:.4f}, NMAE: {nmae_2022:.4f}, NRMSE: {nrmse_2022:.4f}\")\n",
    "\n",
    "    # 记录结果\n",
    "    results.append({\n",
    "        'Run': i+1,\n",
    "        'Training Time (s)': training_time,\n",
    "        'RMSE_2020': rmse_2020, 'MAE_2020': mae_2020, 'R²_2020': r2_2020, 'NMAE_2020': nmae_2020, 'NRMSE_2020': nrmse_2020,\n",
    "        'RMSE_2021': rmse_2021, 'MAE_2021': mae_2021, 'R²_2021': r2_2021, 'NMAE_2021': nmae_2021, 'NRMSE_2021': nrmse_2021,\n",
    "        'RMSE_2022': rmse_2022, 'MAE_2022': mae_2022, 'R²_2022': r2_2022, 'NMAE_2022': nmae_2022, 'NRMSE_2022': nrmse_2022\n",
    "    })\n",
    "\n",
    "# 保存结果到 CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"CNN_LSTM_results.csv\", index=False)\n",
    "print(\"Results saved to CNN_LSTM_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5686780,
     "sourceId": 9375395,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 522.989664,
   "end_time": "2025-03-18T04:29:06.883284",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-18T04:20:23.893620",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
