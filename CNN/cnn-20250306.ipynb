{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126f031e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-11T03:59:12.483864Z",
     "iopub.status.busy": "2025-03-11T03:59:12.483593Z",
     "iopub.status.idle": "2025-03-11T03:59:13.232364Z",
     "shell.execute_reply": "2025-03-11T03:59:13.231352Z"
    },
    "papermill": {
     "duration": 0.753096,
     "end_time": "2025-03-11T03:59:13.233866",
     "exception": false,
     "start_time": "2025-03-11T03:59:12.480770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/all-province/all_province_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d138a586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T03:59:13.238599Z",
     "iopub.status.busy": "2025-03-11T03:59:13.238242Z",
     "iopub.status.idle": "2025-03-11T04:00:19.217382Z",
     "shell.execute_reply": "2025-03-11T04:00:19.216401Z"
    },
    "papermill": {
     "duration": 65.982837,
     "end_time": "2025-03-11T04:00:19.218783",
     "exception": false,
     "start_time": "2025-03-11T03:59:13.235946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "====== Begin CNN Grid Search ======\n",
      "\n",
      "====== CNN Grid Search Completed ======\n",
      "Best Hyperparameters: Learning Rate = 0.005, Hidden Dim = 32, Epochs = 158\n",
      "\n",
      "====== Training CNN Run 1/10 ======\n",
      "Model 1 saved as final_CNN_model_run_1.pth\n",
      "Run 1: Training Time = 0.29 s\n",
      "2020 - RMSE: 3695.1206, MAE: 3026.9262, R²: 0.9395, NMAE: 0.0841, NRMSE: 0.1026\n",
      "2021 - RMSE: 4305.4350, MAE: 3592.1270, R²: 0.9233, NMAE: 0.0978, NRMSE: 0.1172\n",
      "2022 - RMSE: 3958.3301, MAE: 3076.7978, R²: 0.9292, NMAE: 0.0837, NRMSE: 0.1076\n",
      "\n",
      "====== Training CNN Run 2/10 ======\n",
      "Model 2 saved as final_CNN_model_run_2.pth\n",
      "Run 2: Training Time = 0.29 s\n",
      "2020 - RMSE: 2981.8441, MAE: 2391.0245, R²: 0.9606, NMAE: 0.0664, NRMSE: 0.0828\n",
      "2021 - RMSE: 3506.8832, MAE: 3066.6506, R²: 0.9491, NMAE: 0.0835, NRMSE: 0.0955\n",
      "2022 - RMSE: 3253.3739, MAE: 2778.2423, R²: 0.9522, NMAE: 0.0755, NRMSE: 0.0885\n",
      "\n",
      "====== Training CNN Run 3/10 ======\n",
      "Model 3 saved as final_CNN_model_run_3.pth\n",
      "Run 3: Training Time = 0.30 s\n",
      "2020 - RMSE: 3426.3890, MAE: 2719.2053, R²: 0.9480, NMAE: 0.0755, NRMSE: 0.0952\n",
      "2021 - RMSE: 3797.5530, MAE: 3257.3304, R²: 0.9403, NMAE: 0.0887, NRMSE: 0.1034\n",
      "2022 - RMSE: 3593.1704, MAE: 2946.8958, R²: 0.9417, NMAE: 0.0801, NRMSE: 0.0977\n",
      "\n",
      "====== Training CNN Run 4/10 ======\n",
      "Model 4 saved as final_CNN_model_run_4.pth\n",
      "Run 4: Training Time = 0.30 s\n",
      "2020 - RMSE: 3013.0431, MAE: 2471.3942, R²: 0.9598, NMAE: 0.0686, NRMSE: 0.0837\n",
      "2021 - RMSE: 3554.7957, MAE: 3125.5302, R²: 0.9477, NMAE: 0.0851, NRMSE: 0.0968\n",
      "2022 - RMSE: 3223.8367, MAE: 2690.8578, R²: 0.9531, NMAE: 0.0732, NRMSE: 0.0877\n",
      "\n",
      "====== Training CNN Run 5/10 ======\n",
      "Model 5 saved as final_CNN_model_run_5.pth\n",
      "Run 5: Training Time = 0.29 s\n",
      "2020 - RMSE: 2791.4951, MAE: 2269.0343, R²: 0.9655, NMAE: 0.0630, NRMSE: 0.0775\n",
      "2021 - RMSE: 3502.4457, MAE: 2939.1967, R²: 0.9492, NMAE: 0.0800, NRMSE: 0.0953\n",
      "2022 - RMSE: 3761.1734, MAE: 3330.9003, R²: 0.9361, NMAE: 0.0906, NRMSE: 0.1023\n",
      "\n",
      "====== Training CNN Run 6/10 ======\n",
      "Model 6 saved as final_CNN_model_run_6.pth\n",
      "Run 6: Training Time = 0.30 s\n",
      "2020 - RMSE: 2976.9004, MAE: 2449.2071, R²: 0.9607, NMAE: 0.0680, NRMSE: 0.0827\n",
      "2021 - RMSE: 3663.9879, MAE: 3123.9825, R²: 0.9444, NMAE: 0.0850, NRMSE: 0.0997\n",
      "2022 - RMSE: 3198.9869, MAE: 2650.6002, R²: 0.9538, NMAE: 0.0721, NRMSE: 0.0870\n",
      "\n",
      "====== Training CNN Run 7/10 ======\n",
      "Model 7 saved as final_CNN_model_run_7.pth\n",
      "Run 7: Training Time = 0.30 s\n",
      "2020 - RMSE: 3043.9095, MAE: 2427.9765, R²: 0.9589, NMAE: 0.0674, NRMSE: 0.0845\n",
      "2021 - RMSE: 3670.0128, MAE: 3199.6548, R²: 0.9443, NMAE: 0.0871, NRMSE: 0.0999\n",
      "2022 - RMSE: 3351.9582, MAE: 2909.1989, R²: 0.9493, NMAE: 0.0791, NRMSE: 0.0911\n",
      "\n",
      "====== Training CNN Run 8/10 ======\n",
      "Model 8 saved as final_CNN_model_run_8.pth\n",
      "Run 8: Training Time = 0.31 s\n",
      "2020 - RMSE: 3164.3594, MAE: 2600.4619, R²: 0.9556, NMAE: 0.0722, NRMSE: 0.0879\n",
      "2021 - RMSE: 3647.1758, MAE: 3159.9790, R²: 0.9449, NMAE: 0.0860, NRMSE: 0.0993\n",
      "2022 - RMSE: 3321.7264, MAE: 2736.2492, R²: 0.9502, NMAE: 0.0744, NRMSE: 0.0903\n",
      "\n",
      "====== Training CNN Run 9/10 ======\n",
      "Model 9 saved as final_CNN_model_run_9.pth\n",
      "Run 9: Training Time = 0.30 s\n",
      "2020 - RMSE: 3447.0718, MAE: 2772.3700, R²: 0.9473, NMAE: 0.0770, NRMSE: 0.0957\n",
      "2021 - RMSE: 3879.4782, MAE: 3346.3126, R²: 0.9377, NMAE: 0.0911, NRMSE: 0.1056\n",
      "2022 - RMSE: 3671.8036, MAE: 2804.1490, R²: 0.9391, NMAE: 0.0762, NRMSE: 0.0998\n",
      "\n",
      "====== Training CNN Run 10/10 ======\n",
      "Model 10 saved as final_CNN_model_run_10.pth\n",
      "Run 10: Training Time = 0.28 s\n",
      "2020 - RMSE: 3057.1679, MAE: 2496.9989, R²: 0.9586, NMAE: 0.0693, NRMSE: 0.0849\n",
      "2021 - RMSE: 3698.9479, MAE: 3197.8417, R²: 0.9434, NMAE: 0.0870, NRMSE: 0.1007\n",
      "2022 - RMSE: 3308.8673, MAE: 2629.2169, R²: 0.9506, NMAE: 0.0715, NRMSE: 0.0900\n",
      "Results saved to CNN_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "# 种子固定\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)  # 设置 CPU 随机种子\n",
    "torch.cuda.manual_seed(42)  # 设置 GPU 随机种子\n",
    "torch.cuda.manual_seed_all(42)  # 如果使用多 GPU，设置所有 GPU 的随机种子\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# ===============================\n",
    "# 1. 数据预处理\n",
    "# ===============================\n",
    "file_path = '/kaggle/input/all-province/all_province_data.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "data['Year'] = data['时间'].str.extract('(\\d+)').astype(int)\n",
    "data = pd.get_dummies(data, columns=['Province'])\n",
    "\n",
    "# 选择特征\n",
    "features = [\n",
    "    'Year', 'Ammonia Nitrogen Emissions', 'Average Temperature',\n",
    "    'Average Years of Education per Capita', 'Chemical Oxygen Demand Emissions',\n",
    "    'Electricity Consumption', 'Geographic-Mean PM2',\n",
    "    'Government Expenditure on Environmental Protection',\n",
    "    'NOx Emissions', 'Number of Healthcare Institutions',\n",
    "    'Number of Healthcare Personnel', 'Oil Emissions',\n",
    "    'Per Capita Disposable Income', 'Resident Population',\n",
    "    'SO2 Emissions', 'Total Nitrogen Emissions',\n",
    "    'Total Phosphorus Emissions'\n",
    "] + list(data.columns[data.columns.str.startswith('Province_')])\n",
    "\n",
    "X = data[features]\n",
    "y = data['Total CO2 emissions']\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_test_2020 = X[X['Year'] == 2020]\n",
    "X_test_2021 = X[X['Year'] == 2021]\n",
    "X_test_2022 = X[X['Year'] == 2022]\n",
    "y_test_2020 = y[X['Year'] == 2020]\n",
    "y_test_2021 = y[X['Year'] == 2021]\n",
    "y_test_2022 = y[X['Year'] == 2022]\n",
    "X_train_all = X[~X['Year'].isin([2020, 2021, 2022])]\n",
    "y_train_all = y[~X['Year'].isin([2020, 2021, 2022])]\n",
    "\n",
    "# 标准化数据\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train_all_scaled = scaler_x.fit_transform(X_train_all)\n",
    "X_test_2020_scaled = scaler_x.transform(X_test_2020)\n",
    "X_test_2021_scaled = scaler_x.transform(X_test_2021)\n",
    "X_test_2022_scaled = scaler_x.transform(X_test_2022)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_all_scaled = scaler_y.fit_transform(y_train_all.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# ===============================\n",
    "# 2. 定义 CNN 模型\n",
    "# ===============================\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(hidden_dim * input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, num_features)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# ===============================\n",
    "# 3. 五折交叉验证 (超参数选择)\n",
    "# ===============================\n",
    "candidate_learning_rates = [0.001, 0.005, 0.01]\n",
    "candidate_hidden_dims = [32, 64, 128]\n",
    "candidate_patience_values = [10, 20, 30]\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "best_hyperparams = None\n",
    "best_avg_r2 = float('-inf')\n",
    "\n",
    "print(\"\\n====== Begin CNN Grid Search ======\")\n",
    "for lr in candidate_learning_rates:\n",
    "    for hidden_dim in candidate_hidden_dims:\n",
    "        for patience in candidate_patience_values:\n",
    "            fold_r2_scores = []\n",
    "            fold_best_epochs = []\n",
    "\n",
    "            for train_idx, val_idx in kfold.split(X_train_all_scaled):\n",
    "                X_train_fold, X_val_fold = X_train_all_scaled[train_idx], X_train_all_scaled[val_idx]\n",
    "                y_train_fold, y_val_fold = y_train_all_scaled[train_idx], y_train_all_scaled[val_idx]\n",
    "\n",
    "                X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32).to(device)\n",
    "                y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32).to(device)\n",
    "                X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32).to(device)\n",
    "                y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32).to(device)\n",
    "\n",
    "                model = CNNModel(X_train_all.shape[1], hidden_dim, 1).to(device)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                criterion = nn.MSELoss()\n",
    "\n",
    "                best_val_r2 = float('-inf')\n",
    "                best_epoch = 0\n",
    "                no_improve_counter = 0\n",
    "                max_epochs = 200\n",
    "\n",
    "                for epoch in range(max_epochs):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "                    predictions = model(X_train_tensor).squeeze()\n",
    "                    loss = criterion(predictions, y_train_tensor)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        preds_val = model(X_val_tensor).squeeze().cpu().numpy()\n",
    "                    val_r2 = r2_score(y_val_tensor.cpu().numpy(), preds_val)\n",
    "\n",
    "                    if val_r2 > best_val_r2:\n",
    "                        best_val_r2 = val_r2\n",
    "                        best_epoch = epoch + 1\n",
    "                        no_improve_counter = 0\n",
    "                    else:\n",
    "                        no_improve_counter += 1\n",
    "                    if no_improve_counter >= patience:\n",
    "                        break\n",
    "\n",
    "                fold_r2_scores.append(best_val_r2)\n",
    "                fold_best_epochs.append(best_epoch)\n",
    "\n",
    "            avg_r2 = np.mean(fold_r2_scores)\n",
    "            avg_best_epoch = np.mean(fold_best_epochs)\n",
    "\n",
    "            if avg_r2 > best_avg_r2:\n",
    "                best_avg_r2 = avg_r2\n",
    "                best_hyperparams = (lr, hidden_dim, avg_best_epoch)\n",
    "\n",
    "print(\"\\n====== CNN Grid Search Completed ======\")\n",
    "best_learning_rate, best_hidden_dim, final_num_epochs = best_hyperparams\n",
    "print(f\"Best Hyperparameters: Learning Rate = {best_learning_rate}, Hidden Dim = {best_hidden_dim}, Epochs = {int(final_num_epochs)}\")\n",
    "\n",
    "# ===============================\n",
    "# 4. 计算 RMSE、MAE、R²、NMAE、NRMSE\n",
    "# ===============================\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    X_test_scaled = scaler_x.transform(X_test)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_test = model(X_test_tensor).squeeze().cpu().numpy()\n",
    "    preds_test_unscaled = scaler_y.inverse_transform(preds_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds_test_unscaled))\n",
    "    mae = mean_absolute_error(y_test, preds_test_unscaled)\n",
    "    r2 = r2_score(y_test, preds_test_unscaled)\n",
    "    nmae = mae / np.mean(y_test) if np.mean(y_test) != 0 else np.nan\n",
    "    nrmse = rmse / np.mean(y_test) if np.mean(y_test) != 0 else np.nan\n",
    "\n",
    "    return rmse, mae, r2, nmae, nrmse\n",
    "\n",
    "# ===============================\n",
    "# 5. 10 次训练，保存结果\n",
    "# ===============================\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"\\n====== Training CNN Run {i+1}/10 ======\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 初始化 CNN 模型\n",
    "    model = CNNModel(X_train_all.shape[1], best_hidden_dim, 1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(int(final_num_epochs)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(torch.tensor(X_train_all_scaled, dtype=torch.float32).to(device)).squeeze()\n",
    "        loss = criterion(predictions, torch.tensor(y_train_all_scaled, dtype=torch.float32).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 计算训练时间\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # 保存模型\n",
    "    model_filename = f'final_CNN_model_run_{i+1}.pth'\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print(f\"Model {i+1} saved as {model_filename}\")\n",
    "\n",
    "    # 评估模型在 2020、2021、2022 上的表现\n",
    "    rmse_2020, mae_2020, r2_2020, nmae_2020, nrmse_2020 = evaluate_model(model, X_test_2020, y_test_2020)\n",
    "    rmse_2021, mae_2021, r2_2021, nmae_2021, nrmse_2021 = evaluate_model(model, X_test_2021, y_test_2021)\n",
    "    rmse_2022, mae_2022, r2_2022, nmae_2022, nrmse_2022 = evaluate_model(model, X_test_2022, y_test_2022)\n",
    "\n",
    "    print(f\"Run {i+1}: Training Time = {training_time:.2f} s\")\n",
    "    print(f\"2020 - RMSE: {rmse_2020:.4f}, MAE: {mae_2020:.4f}, R²: {r2_2020:.4f}, NMAE: {nmae_2020:.4f}, NRMSE: {nrmse_2020:.4f}\")\n",
    "    print(f\"2021 - RMSE: {rmse_2021:.4f}, MAE: {mae_2021:.4f}, R²: {r2_2021:.4f}, NMAE: {nmae_2021:.4f}, NRMSE: {nrmse_2021:.4f}\")\n",
    "    print(f\"2022 - RMSE: {rmse_2022:.4f}, MAE: {mae_2022:.4f}, R²: {r2_2022:.4f}, NMAE: {nmae_2022:.4f}, NRMSE: {nrmse_2022:.4f}\")\n",
    "\n",
    "    # 记录结果\n",
    "    results.append({\n",
    "        'Run': i+1,\n",
    "        'Training Time (s)': training_time,\n",
    "        'RMSE_2020': rmse_2020, 'MAE_2020': mae_2020, 'R²_2020': r2_2020, 'NMAE_2020': nmae_2020, 'NRMSE_2020': nrmse_2020,\n",
    "        'RMSE_2021': rmse_2021, 'MAE_2021': mae_2021, 'R²_2021': r2_2021, 'NMAE_2021': nmae_2021, 'NRMSE_2021': nrmse_2021,\n",
    "        'RMSE_2022': rmse_2022, 'MAE_2022': mae_2022, 'R²_2022': r2_2022, 'NMAE_2022': nmae_2022, 'NRMSE_2022': nrmse_2022\n",
    "    })\n",
    "\n",
    "# 保存结果到 CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"CNN_results.csv\", index=False)\n",
    "print(\"Results saved to CNN_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5686780,
     "sourceId": 9375395,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.838578,
   "end_time": "2025-03-11T04:00:21.694787",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-11T03:59:09.856209",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
